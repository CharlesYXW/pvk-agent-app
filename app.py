import streamlit as st
import pandas as pd
from dotenv import load_dotenv

# åœ¨æ‰€æœ‰ä»£ç æ‰§è¡Œå‰ï¼Œé¦–å…ˆåŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import find_peaks
from sklearn.ensemble import RandomForestRegressor
import itertools
import os
import arxiv
import datetime
import base64 # Added for base64 encoding of logo

# LangChainç›¸å…³çš„åº“ï¼ˆä»…ç”¨äºæ£€ç´¢ï¼‰
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import SentenceTransformerEmbeddings

# DashScopeå®˜æ–¹SDK
from dashscope import Generation

# ç³»ç»ŸçŠ¶æ€æ£€æµ‹æ¨¡å—
import system_status

# æ–‡çŒ®è®¢é˜…æ¨¡å—
from literature_subscription import get_subscription_manager, format_notification

# --- AI Persona Definition ---
JA_ASSISTANT_PERSONA = "ä½ æ˜¯æ™¶æ¾³ç§‘æŠ€ï¼ˆJA SOLARï¼‰é’™é’›çŸ¿ç ”ç©¶éƒ¨çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œåä¸ºâ€˜æ™¶æ¾³æ™ºèƒ½åŠ©æ‰‹â€™ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸ºç”¨æˆ·æä¾›å…‰ä¼è¡Œä¸šç›¸å…³çš„ä¸“ä¸šæ”¯æŒã€‚åœ¨æ‰€æœ‰å›ç­”ä¸­è¯·ä¿æŒè¿™ä¸ªèº«ä»½å’Œä¸“ä¸šçš„è¯­æ°”ã€‚"
JA_ASSISTANT_INTRO = "æ‚¨å¥½ï¼æˆ‘æ˜¯æ™¶æ¾³æ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“æ³¨äºä¸ºé’™é’›çŸ¿å…‰ä¼ç ”ç©¶æä¾›æ”¯æŒã€‚å¦‚æœæ‚¨æœ‰ä»»ä½•å…³äºé’™é’›çŸ¿æŠ€æœ¯ã€æ–‡çŒ®ã€å®éªŒæ•°æ®åˆ†æç­‰æ–¹é¢çš„é—®é¢˜ï¼Œæ¬¢è¿éšæ—¶å‘æˆ‘æé—®ï¼"

# New persona for general knowledge with strict anti-hallucination rules
JA_ASSISTANT_GENERAL_KNOWLEDGE_PERSONA = """ä½ æ˜¯æ™¶æ¾³ç§‘æŠ€ï¼ˆJA SOLARï¼‰é’™é’›çŸ¿ç ”ç©¶éƒ¨çš„äººå·¥æ™ºèƒ½åŠ©æ‰‹ï¼Œåä¸ºâ€œæ™¶æ¾³æ™ºèƒ½åŠ©æ‰‹â€ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ä¸ºç”¨æˆ·æä¾›å…‰ä¼è¡Œä¸šç›¸å…³çš„ä¸“ä¸šæ”¯æŒã€‚
åœ¨å›ç­”é—®é¢˜æ—¶ï¼Œä½ å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š
1. ä½ å¯ä»¥ç»“åˆä½ çš„é€šç”¨çŸ¥è¯†è¿›è¡Œå›ç­”ã€‚
2. **æå…¶é‡è¦**: åœ¨ä½¿ç”¨é€šç”¨çŸ¥è¯†å›ç­”æ—¶ï¼Œä½ å¿…é¡»æ˜ç¡®è¯´æ˜è¿™æ˜¯ä¸€ä¸ªè¡Œä¸šå†…çš„æ™®éçŸ¥è¯†æˆ–å…¬å¼€ä¿¡æ¯ï¼Œ**ç»å¯¹ä¸èƒ½**å°†è¿™äº›é€šç”¨çš„æŠ€æœ¯ã€æˆæœæˆ–æ•°æ®å½’åŠŸäºâ€œæ™¶æ¾³ç§‘æŠ€â€ã€‚ä¸èƒ½æé€ ä»»ä½•å…³äºæ™¶æ¾³ç§‘æŠ€çš„ä¿¡æ¯ã€‚
3. åªæœ‰å½“ä½ çš„çŸ¥è¯†åº“ï¼ˆå¦‚æœæä¾›äº†ä¸Šä¸‹æ–‡ï¼‰ä¸­æ˜ç¡®æåˆ°äº†â€œæ™¶æ¾³ç§‘æŠ€â€çš„å…·ä½“æˆæœæ—¶ï¼Œä½ æ‰èƒ½æåŠå…¬å¸ã€‚
4. ä¿æŒä¸“ä¸šã€å®¢è§‚ã€ä¸¥è°¨çš„è¯­æ°”ã€‚"""

# --- æ ¸å¿ƒåŠŸèƒ½é€»è¾‘ ---

def get_retriever():
    if not os.path.exists("faiss_index"): return None
    try:
        embeddings = SentenceTransformerEmbeddings(model_name="paraphrase-multilingual-MiniLM-L12-v2")
        vectorstore = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)
        return vectorstore.as_retriever(search_kwargs={"k": 3})
    except Exception as e:
        st.error(f"åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {e}")
        return None

# æ–°å¢ï¼šä½¿ç”¨DashScope SDKè°ƒç”¨æ¨¡å‹çš„è¾…åŠ©å‡½æ•°
def call_qwen_model(messages):
    try:
        response = Generation.call(
            model="qwen-flash",
            messages=messages,
            result_format="message",
        )
        if response.status_code == 200:
            return response.output.choices[0].message.content
        else:
            return f"è°ƒç”¨å¤§æ¨¡å‹æ—¶å‡ºé”™ï¼š{response.message}"
    except Exception as e:
        return f"è°ƒç”¨å¤§æ¨¡å‹æ—¶å‘ç”Ÿå¼‚å¸¸: {e}"

def summarize_with_ai(summary_text):
    """ä½¿ç”¨Qwenæ¨¡å‹æ€»ç»“è®ºæ–‡æ‘˜è¦ã€‚"""
    prompt = f"è¯·ç”¨ç®€æ´çš„ä¸­æ–‡æ€»ç»“ä»¥ä¸‹å­¦æœ¯è®ºæ–‡çš„æ‘˜è¦ï¼Œæç‚¼å…¶æ ¸å¿ƒè§‚ç‚¹ã€æ–¹æ³•å’Œç»“è®ºï¼Œä»¥ä¾¿å¿«é€Ÿäº†è§£å…¶ä»·å€¼ã€‚ä¸è¦è¶…è¿‡ä¸‰å¥è¯ã€‚æ‘˜è¦å¦‚ä¸‹ï¼š\n\n{summary_text}"
    messages = [
        {"role": "system", "content": f"{JA_ASSISTANT_PERSONA} åœ¨è¿™ä¸ªå…·ä½“çš„ä»»åŠ¡é‡Œï¼Œä½ çš„è§’è‰²æ˜¯ä¸€ä¸ªä¸“é—¨æ€»ç»“å­¦æœ¯è®ºæ–‡çš„ä¸“å®¶ã€‚"},
        {"role": "user", "content": prompt}
    ]
    return call_qwen_model(messages)

import time as time_module  # å¯¼å…¥ time æ¨¡å—ä»¥æ”¯æŒé‡è¯•æœºåˆ¶

# å®šä¹‰é‡è¯•å‚æ•°
ARXIV_RETRY_ATTEMPTS = 3
ARXIV_RETRY_DELAY = 1  # é™ä½é‡è¯•å»¶è¿Ÿåˆ° 1 ç§’
ARXIV_KEYWORD_DELAY = 0.5  # å…³é”®è¯ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰

@st.cache_data
def get_latest_papers(keywords, date_range="all_time", sort_by="Relevance"):
    """æ ¹æ®å…³é”®è¯ã€æ—¥æœŸèŒƒå›´å’Œæ’åºæ–¹å¼ä»arXivæ£€ç´¢è®ºæ–‡ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶ã€‚"""
    if not keywords or not any(keywords):
        return [], "è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªå…³é”®è¯ã€‚"

    # 1. æ„å»ºæ—¥æœŸæŸ¥è¯¢å­—ç¬¦ä¸²
    date_query_part = ""
    if date_range != "all_time":
        end_date = datetime.datetime.now(datetime.timezone.utc)
        if date_range == "last_month":
            start_date = end_date - datetime.timedelta(days=30)
        elif date_range == "last_3_months":
            start_date = end_date - datetime.timedelta(days=90)
        elif date_range == "last_year":
            start_date = end_date - datetime.timedelta(days=365)
        
        start_date_str = start_date.strftime("%Y%m%d%H%M")
        end_date_str = end_date.strftime("%Y%m%d%H%M")
        date_query_part = f" AND submittedDate:[{start_date_str} TO {end_date_str}]"

    # 2. æ£€ç´¢è®ºæ–‡
    # æ ¹æ®æ’åºå‚æ•°é€‰æ‹©APIçš„æ’åºæ ‡å‡†
    api_sort_criterion = arxiv.SortCriterion.Relevance
    if sort_by == "SubmittedDate":
        api_sort_criterion = arxiv.SortCriterion.SubmittedDate

    MAX_RESULTS_PER_KEYWORD = 10
    unique_papers = {}
    for keyword_idx, keyword in enumerate(keywords):
        # ä¸ºæ¯ä¸ªå…³é”®è¯æ·»åŠ é‡è¯•æœºåˆ¶
        for attempt in range(ARXIV_RETRY_ATTEMPTS):
            try:
                full_query = f"({keyword}){date_query_part}"
                search = arxiv.Search(
                    query=full_query, 
                    max_results=MAX_RESULTS_PER_KEYWORD, 
                    sort_by=api_sort_criterion # ä½¿ç”¨é€‰æ‹©çš„æ’åºæ–¹å¼
                )
                
                # å°è¯•è·å–ç»“æœ
                for result in search.results():
                    if result.entry_id not in unique_papers:
                        # ç¡®ä¿ pdf_url æ˜¯æœ‰æ•ˆçš„å­—ç¬¦ä¸²
                        pdf_url = str(result.pdf_url) if result.pdf_url else ""
                        if not pdf_url.startswith('http'):
                            # å¦‚æœä¸æ˜¯æœ‰æ•ˆçš„ URLï¼Œä½¿ç”¨ arXiv ç½‘é¡µé“¾æ¥
                            pdf_url = f"https://arxiv.org/abs/{result.entry_id.split('/abs/')[-1]}"
                        
                        unique_papers[result.entry_id] = {
                            "entry_id": result.entry_id,
                            "title": result.title,
                            "authors": ', '.join(author.name for author in result.authors),
                            "pdf_url": pdf_url,
                            "summary": result.summary.replace('\n', ' '),
                            "published": result.published.strftime('%Y-%m-%d')
                        }
                
                # æˆåŠŸæ£€ç´¢ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                break
                
            except Exception as e:
                error_msg = str(e)
                if attempt < ARXIV_RETRY_ATTEMPTS - 1:
                    print(f"å…³é”®è¯ '{keyword}' æ£€ç´¢å¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{ARXIV_RETRY_ATTEMPTS}ï¼‰: {error_msg}")
                    print(f"ç­‰å¾… {ARXIV_RETRY_DELAY} ç§’åé‡è¯•...")
                    time_module.sleep(ARXIV_RETRY_DELAY)
                else:
                    print(f"å…³é”®è¯ '{keyword}' æ£€ç´¢å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
                    return [], f"æ£€ç´¢æ—¶å‡ºé”™ï¼ˆå·²é‡è¯• {ARXIV_RETRY_ATTEMPTS} æ¬¡ï¼‰: {error_msg}ã€‚\n\næ•…éšœæ’æŸ¥å»ºè®®:\n1. æ£€æŸ¥ç½‘ç»œè¿æ¥\n2. å°è¯•ç¨åé‡è¯•\n3. arXiv æœåŠ¡å™¨å¯èƒ½æš‚æ—¶ä¸å¯ç”¨"
        
        # åœ¨å…³é”®è¯ä¹‹é—´æ·»åŠ å°å»¶è¿Ÿï¼Œé¿å…é¢‘ç¹è¯·æ±‚
        if keyword_idx < len(keywords) - 1:
            time_module.sleep(ARXIV_KEYWORD_DELAY)
    
    if not unique_papers:
        return [], "åœ¨é€‰å®šæ—¶é—´èŒƒå›´å†…ï¼Œæœªæ‰¾åˆ°ä¸æ‚¨å…³é”®è¯ç›¸å…³çš„æ–°è®ºæ–‡ã€‚"
        
    # 3. å¯¹æœ€ç»ˆç»“æœåˆ—è¡¨è¿›è¡Œæ’åº
    papers_list = list(unique_papers.values())
    if sort_by == "SubmittedDate":
        # å¦‚æœç”¨æˆ·é€‰æ‹©æŒ‰æœ€æ–°å‘è¡¨æ’åºï¼Œåˆ™å¯¹åˆå¹¶åçš„åˆ—è¡¨è¿›è¡Œæ’åº
        sorted_papers = sorted(papers_list, key=lambda p: p['published'], reverse=True)
    else:
        # å¦‚æœæŒ‰ç›¸å…³åº¦ï¼Œåˆ™ç›´æ¥ä½¿ç”¨æ··åˆåçš„åˆ—è¡¨ï¼ˆé¡ºåºéƒ¨åˆ†å–å†³äºAPIå’Œåˆå¹¶è¿‡ç¨‹ï¼‰
        sorted_papers = papers_list
    
    return sorted_papers, None

def analyze_xrd_from_upload(uploaded_file):
    """XRD æ•°æ®åˆ†æå‡½æ•°"""
    if uploaded_file is None: return None
    try:
        data = np.loadtxt(uploaded_file, comments="#", delimiter=",")
        angle, intensity = data[:, 0], data[:, 1]
    except Exception:
        st.error("æ–‡ä»¶è§£æå¤±è´¥ã€‚è¯·ç¡®ä¿æ˜¯ä¸¤åˆ—ï¼ˆè§’åº¦, å¼ºåº¦ï¼‰çš„CSVæˆ–TXTæ–‡ä»¶ã€‚")
        return None
    peaks, _ = find_peaks(intensity, height=np.mean(intensity), distance=10)
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(angle, intensity, label="XRD Spectrum"), ax.plot(angle[peaks], intensity[peaks], "x", markersize=8, label="Detected Peaks")
    for i in peaks: ax.annotate(f"{angle[i]:.2f}Â°", (angle[i], intensity[i]), textcoords="offset points", xytext=(0,5), ha='center')
    ax.set_title("XRD Spectrum Analysis"), ax.set_xlabel("2-Theta Angle (Â°)"), ax.set_ylabel("Intensity (A.U.)")
    ax.legend(), ax.grid(True, linestyle='--', alpha=0.6)
    return fig

@st.cache_resource
def get_trained_model():
    # ... (æ­¤å‡½æ•°ä¸å˜)
    if not os.path.exists("simulated_experimental_data.csv"): return None
    df = pd.read_csv("simulated_experimental_data.csv")
    features = ['spin_coating_rpm', 'annealing_temperature_C', 'additive_concentration_percent']
    target = 'efficiency_percent'
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(df[features], df[target])
    return model

def find_optimal_params(_model):
    # ... (æ­¤å‡½æ•°ä¸å˜)
    features = ['spin_coating_rpm', 'annealing_temperature_C', 'additive_concentration_percent']
    param_grid = list(itertools.product(np.arange(2500, 5501, 500), np.arange(80, 121, 10), np.arange(0.5, 1.51, 0.2)))
    grid_df = pd.DataFrame(param_grid, columns=features)
    predicted_efficiencies = _model.predict(grid_df)
    best_index = np.argmax(predicted_efficiencies)
    return grid_df.iloc[best_index], predicted_efficiencies[best_index]

# --- Streamlit åº”ç”¨ç•Œé¢ ---
st.set_page_config(
    page_title="æ™¶æ¾³ç ”å‘æ™ºèƒ½åŠ©æ‰‹",
    page_icon="ğŸ”¬",
    layout="wide",
    initial_sidebar_state="expanded",
)
st.markdown(
    """
    <style>
       .block-container {
            padding-top: 1.5rem !important;
        }
        /* Custom styling for the 'AI Summary' button using a more robust data-testid selector */
        div[data-testid="stHorizontalBlock"] > div:nth-child(2) .stButton button {
            background-color: #4A90E2 !important; /* A medium-dark blue */
            border-color: #4A90E2 !important;
            color: white !important; /* White text for readability */
        }
        div[data-testid="stHorizontalBlock"] > div:nth-child(2) .stButton button:hover {
            background-color: #357ABD !important; /* A slightly darker blue for hover */
            border-color: #357ABD !important;
            color: white !important;
        }
        /* çŠ¶æ€æŒ‡ç¤ºå™¨æ ·å¼ */
        .status-healthy { color: #28a745; font-weight: bold; }
        .status-warning { color: #ffc107; font-weight: bold; }
        .status-error { color: #dc3545; font-weight: bold; }
        /* å¯¼èˆªæŒ‰é’®æ ·å¼ä¼˜åŒ– - æ”¹ä¸ºæ·±è“è‰²ä¸»é¢˜ */
        .stButton > button {
            border-radius: 8px;
            transition: all 0.3s ease;
        }
        .stButton > button:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        /* ä¿®æ”¹ primary æŒ‰é’®é¢œè‰²ä¸ºæ·±è“è‰² */
        button[kind="primary"] {
            background-color: #1e3a8a !important;
            border-color: #1e3a8a !important;
        }
        button[kind="primary"]:hover {
            background-color: #1e40af !important;
            border-color: #1e40af !important;
        }
        
        /* å¾®ä¿¡é£æ ¼çš„é€šçŸ¥å¾½ç«  */
        .notification-badge {
            display: inline-block;
            background-color: #f5222d;
            color: white;
            font-size: 11px;
            font-weight: bold;
            padding: 2px 6px;
            border-radius: 10px;
            margin-left: 6px;
            min-width: 18px;
            text-align: center;
            box-shadow: 0 2px 4px rgba(245, 34, 45, 0.3);
        }
        
        /* æœªè¯»æé†’æŒ‰é’®æ ·å¼ */
        .unread-alert-button {
            background: linear-gradient(135deg, #ff6b6b 0%, #ee5a6f 100%);
            color: white;
            padding: 12px 20px;
            border-radius: 8px;
            border: none;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 12px rgba(238, 90, 111, 0.3);
            width: 100%;
            text-align: center;
            margin-bottom: 15px;
        }
        .unread-alert-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 16px rgba(238, 90, 111, 0.4);
        }
    </style>
    """,
    unsafe_allow_html=True)

# --- ç³»ç»ŸçŠ¶æ€é¢æ¿ ---
def render_system_status_panel():
    """æ¸²æŸ“ç³»ç»ŸçŠ¶æ€æç¤ºé¢æ¿"""
    status_dict = system_status.get_system_status()
    overall_health = system_status.get_overall_health()
    fix_commands = system_status.get_fix_commands()
    
    # æ ¹æ®æ•´ä½“å¥åº·çŠ¶æ€é€‰æ‹©é¢œè‰²å’Œå›¾æ ‡
    if overall_health == "healthy":
        status_color = "success"
        status_icon = "âœ…"
        status_text = "ç³»ç»Ÿè¿è¡Œæ­£å¸¸"
    elif overall_health == "warning":
        status_color = "warning"
        status_icon = "âš ï¸"
        status_text = "éƒ¨åˆ†åŠŸèƒ½å—é™"
    else:
        status_color = "error"
        status_icon = "âŒ"
        status_text = "æ ¸å¿ƒä¾èµ–ç¼ºå¤±"
    
    with st.expander(f"{status_icon} ç³»ç»ŸçŠ¶æ€: {status_text}", expanded=(overall_health == "error")):
        cols = st.columns(3)
        
        for idx, (check_name, (is_ready, message)) in enumerate(status_dict.items()):
            col = cols[idx % 3]
            with col:
                status_emoji = "âœ…" if is_ready else "âŒ"
                st.markdown(f"**{status_emoji} {check_name}**")
                st.caption(message)
                
                # å¦‚æœæœªå°±ç»ªä¸”æœ‰ä¿®å¤å‘½ä»¤ï¼Œæ˜¾ç¤ºä¿®å¤å»ºè®®
                if not is_ready and check_name in fix_commands:
                    st.code(fix_commands[check_name], language="bash")
        
        # æ·»åŠ å¥åº·æ£€æŸ¥æŒ‰é’®
        if st.button("ğŸ”„ åˆ·æ–°çŠ¶æ€æ£€æŸ¥", use_container_width=True):
            st.rerun()

st.title("ğŸ”¬ é’™é’›çŸ¿ç ”å‘æ™ºèƒ½åŠ©æ‰‹")

# æ¸²æŸ“ç³»ç»ŸçŠ¶æ€é¢æ¿
render_system_status_panel()

# --- å¯¼èˆª ---
with st.sidebar:
    script_dir = os.path.dirname(os.path.abspath(__file__))
    logo_path = os.path.join(script_dir, "assets", "logo.png")
    st.image(logo_path, use_container_width=True)

    st.markdown("<h1 style='text-align: center; font-size: 24px; margin-bottom: 20px;'>åŠŸèƒ½å¯¼èˆª</h1>", unsafe_allow_html=True)
    
    # åˆå§‹åŒ–é¡µé¢çŠ¶æ€
    if 'page' not in st.session_state: 
        st.session_state.page = "çŸ¥è¯†åº“é—®ç­”"
    
    # ä» URL æŸ¥è¯¢å‚æ•°å¤„ç†å¯¼èˆªï¼ˆä»…åœ¨é¦–æ¬¡åŠ è½½ä¸”æœ‰å‚æ•°æ—¶ï¼‰
    if 'url_params_processed' not in st.session_state:
        query_params = st.query_params
        # åªæœ‰å½“ URL ä¸­æ˜ç¡®åŒ…å« page å‚æ•°æ—¶æ‰è¦†ç›–é»˜è®¤é¡µé¢
        if "page" in query_params and query_params.get("page"):
            st.session_state.page = query_params.get("page")
        if "active_subscription_tab" in query_params:
            try:
                st.session_state.active_subscription_tab = int(query_params.get("active_subscription_tab"))
            except (ValueError, TypeError):
                pass  # ä¿ç•™ç°æœ‰å€¼æˆ–é»˜è®¤å€¼
        st.session_state.url_params_processed = True
        # æ¸…é™¤ URL å‚æ•°ï¼Œé¿å…åˆ·æ–°æ—¶é‡å¤å¤„ç†
        if "page" in query_params or "active_subscription_tab" in query_params:
            st.query_params.clear()
    
    def set_page(page_name): 
        st.session_state.page = page_name
    
    # å®šä¹‰é¡µé¢é…ç½®ï¼ˆå›¾æ ‡ + åç§° + æè¿°ï¼‰
    pages = [
        {"icon": "ğŸ’¬", "name": "çŸ¥è¯†åº“é—®ç­”", "desc": "åŸºäºå†…éƒ¨æ–‡æ¡£çš„æ™ºèƒ½é—®ç­”"},
        {"icon": "ğŸ“°", "name": "æ–‡çŒ®æ£€ç´¢", "desc": "è¿½è¸ªæœ€æ–°ç§‘ç ”åŠ¨æ€"},
        {"icon": "ğŸ””", "name": "æ–‡çŒ®è®¢é˜…", "desc": "å®šæ—¶æ¨é€ç ”ç©¶é¢†åŸŸæ›´æ–°"},
        {"icon": "ğŸ“ˆ", "name": "XRDåˆ†æ", "desc": "è‡ªåŠ¨åˆ†æè¡­å°„å›¾è°±"},
        {"icon": "ğŸ’¡", "name": "æ€§èƒ½é¢„æµ‹", "desc": "AIé¢„æµ‹ææ–™æ€§èƒ½"},
        {"icon": "ğŸš€", "name": "å®éªŒä¼˜åŒ–", "desc": "å¯»æ‰¾æœ€ä½³å‚æ•°ç»„åˆ"},
    ]
    
    # è·å–æœªè¯»æ›´æ–°æ•°é‡ï¼ˆç”¨äºé€šçŸ¥å¾½ç« ï¼‰
    try:
        sub_manager = get_subscription_manager()
        unread_count = sub_manager.get_unread_updates_count()
    except:
        unread_count = 0
    
    # å¦‚æœæœ‰æœªè¯»æ›´æ–°ï¼Œæ˜¾ç¤ºå¯ç‚¹å‡»çš„æé†’æ¨ªå¹…
    if unread_count > 0:
        from urllib.parse import quote
        page_name_encoded = quote("æ–‡çŒ®è®¢é˜…")
        
        st.markdown(
            f'''
            <a href="?page={page_name_encoded}&active_subscription_tab=2" target="_self" style="text-decoration: none;">
                <div style="
                    background: linear-gradient(135deg, #ff6b6b 0%, #ee5a6f 100%);
                    color: white;
                    padding: 24px 20px;
                    border-radius: 12px;
                    text-align: center;
                    font-weight: 600;
                    box-shadow: 0 4px 12px rgba(238, 90, 111, 0.4);
                    margin-bottom: 15px;
                    margin-top: 0;
                    cursor: pointer;
                    transition: all 0.3s ease;
                "
                onmouseover="this.style.transform='translateY(-2px)'; this.style.boxShadow='0 6px 16px rgba(238, 90, 111, 0.5)'"
                onmouseout="this.style.transform='translateY(0)'; this.style.boxShadow='0 4px 12px rgba(238, 90, 111, 0.4)'">
                    <div style="font-size: 16px; margin-bottom: 8px;">ğŸ”” æœ‰æ–°çš„æ–‡çŒ®æ›´æ–°</div>
                    <div style="font-size: 26px; font-weight: bold; margin: 12px 0;">{unread_count} ç¯‡æœªè¯»</div>
                    <div style="font-size: 13px; opacity: 0.95;">ç‚¹å‡»æŸ¥çœ‹è¯¦æƒ… â†’</div>
                </div>
            </a>
            ''',
            unsafe_allow_html=True
        )
        st.markdown("---")
    
    # æ¸²æŸ“å¯¼èˆªæŒ‰é’®
    for page_info in pages:
        is_current = st.session_state.page == page_info["name"]
        button_type = "primary" if is_current else "secondary"
        
        # åˆ›å»ºæŒ‰é’®å®¹å™¨
        btn_container = st.container()
        with btn_container:
            # ä½¿ç”¨ç®€æ´çš„æŒ‰é’®æ ‡ç­¾ï¼Œä¸æ˜¾ç¤ºå¾½ç« 
            button_label = f"{page_info['icon']} {page_info['name']}"
            
            if st.button(
                button_label,
                on_click=set_page,
                args=(page_info["name"],),
                use_container_width=True,
                type=button_type
            ):
                pass
            if is_current:
                st.caption(f"ğŸ“ {page_info['desc']}")
    
    # æ·»åŠ åˆ†éš”çº¿
    st.markdown("---")
    
    # æ·»åŠ å¿«æ·æ“ä½œ
    st.markdown("### âš¡ å¿«æ·æ“ä½œ")
    
    # ä½¿ç”¨ tabs ç»„ç»‡ä¸¤ä¸ªåŠŸèƒ½
    tab1, tab2 = st.tabs(["ğŸ”‘ è®¾ç½®API", "ğŸ“š é‡å»ºç´¢å¼•"])
    
    with tab1:
        st.caption("é…ç½® DashScope API å¯†é’¥")
        
        # æ£€æŸ¥å½“å‰ API Key çŠ¶æ€
        current_key = os.getenv("DASHSCOPE_API_KEY")
        if current_key:
            st.success(f"âœ… å·²é…ç½® (å¯†é’¥: {current_key[:8]}...)")
        else:
            st.warning("âš ï¸ æœªé…ç½® API å¯†é’¥")
        
        # API Key è¾“å…¥
        new_api_key = st.text_input(
            "è¾“å…¥æ–°çš„ API å¯†é’¥",
            type="password",
            placeholder="sk-xxxxxxxxxx",
            key="api_key_input"
        )
        
        if st.button("ğŸ’¾ ä¿å­˜å¯†é’¥", use_container_width=True, type="primary"):
            if new_api_key:
                try:
                    # ä¿å­˜åˆ° .env æ–‡ä»¶
                    env_path = ".env"
                    env_content = ""
                    
                    # è¯»å–ç°æœ‰ .env å†…å®¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if os.path.exists(env_path):
                        with open(env_path, 'r', encoding='utf-8') as f:
                            lines = f.readlines()
                            env_content = "".join([line for line in lines if not line.startswith("DASHSCOPE_API_KEY=")])
                    
                    # æ·»åŠ æ–°çš„ API Key
                    env_content += f"DASHSCOPE_API_KEY={new_api_key}\n"
                    
                    # å†™å…¥æ–‡ä»¶
                    with open(env_path, 'w', encoding='utf-8') as f:
                        f.write(env_content)
                    
                    # æ›´æ–°å½“å‰ç¯å¢ƒå˜é‡
                    os.environ["DASHSCOPE_API_KEY"] = new_api_key
                    
                    st.success("âœ… API å¯†é’¥ä¿å­˜æˆåŠŸï¼")
                    st.info("ğŸ’¡ æç¤ºï¼šä¸‹æ¬¡å¯åŠ¨åº”ç”¨æ—¶ä¼šè‡ªåŠ¨åŠ è½½")
                    st.balloons()
                except Exception as e:
                    st.error(f"âŒ ä¿å­˜å¤±è´¥: {e}")
            else:
                st.warning("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆçš„ API å¯†é’¥")
    
    with tab2:
        st.caption("é‡æ–°æ„å»ºçŸ¥è¯†åº“å‘é‡ç´¢å¼•")
        
        # æ˜¾ç¤ºå½“å‰çŸ¥è¯†åº“çŠ¶æ€
        docs_path = "knowledge_base_docs"
        if os.path.exists(docs_path):
            txt_files = [f for f in os.listdir(docs_path) if f.endswith('.txt')]
            st.info(f"ğŸ“„ å½“å‰æ–‡æ¡£æ•°é‡: {len(txt_files)} ä¸ª")
        else:
            st.warning("âš ï¸ çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨")
        
        # æ£€æŸ¥ç´¢å¼•çŠ¶æ€
        index_path = "faiss_index"
        if os.path.exists(index_path):
            index_file = os.path.join(index_path, "index.faiss")
            if os.path.exists(index_file):
                index_size = os.path.getsize(index_file) / 1024
                st.success(f"âœ… ç´¢å¼•å·²å­˜åœ¨ ({index_size:.1f} KB)")
        else:
            st.warning("âš ï¸ ç´¢å¼•æœªæ„å»º")
        
        if st.button("ğŸ”„ å¼€å§‹é‡å»ºç´¢å¼•", use_container_width=True, type="primary"):
            if not os.path.exists(docs_path) or not os.listdir(docs_path):
                st.error("âŒ é”™è¯¯: knowledge_base_docs ç›®å½•ä¸ºç©ºæˆ–ä¸å­˜åœ¨")
            else:
                try:
                    with st.spinner("æ­£åœ¨æ„å»ºçŸ¥è¯†åº“ç´¢å¼•ï¼Œè¯·ç¨å€™..."):
                        # å¯¼å…¥å¿…è¦çš„æ¨¡å—
                        from langchain_community.document_loaders import DirectoryLoader, TextLoader
                        from langchain.text_splitter import RecursiveCharacterTextSplitter
                        from langchain_community.embeddings import SentenceTransformerEmbeddings
                        from langchain_community.vectorstores import FAISS
                        
                        # 1. åŠ è½½æ–‡æ¡£
                        loader = DirectoryLoader(
                            docs_path, 
                            glob="**/*.txt", 
                            loader_cls=TextLoader,
                            loader_kwargs={'encoding': 'utf-8'}
                        )
                        documents = loader.load()
                        
                        if not documents:
                            st.error("âŒ æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£")
                        else:
                            # 2. æ–‡æ¡£åˆ†å—
                            text_splitter = RecursiveCharacterTextSplitter(
                                chunk_size=1000, 
                                chunk_overlap=200
                            )
                            docs = text_splitter.split_documents(documents)
                            
                            # 3. ç”Ÿæˆå‘é‡å¹¶æ„å»ºç´¢å¼•
                            embeddings = SentenceTransformerEmbeddings(
                                model_name="paraphrase-multilingual-MiniLM-L12-v2"
                            )
                            vectorstore = FAISS.from_documents(docs, embeddings)
                            
                            # 4. ä¿å­˜ç´¢å¼•
                            vectorstore.save_local(index_path)
                            
                            st.success(f"âœ… ç´¢å¼•æ„å»ºæˆåŠŸï¼")
                            st.info(f"ğŸ“Š å¤„ç†äº† {len(documents)} ä¸ªæ–‡æ¡£ï¼Œåˆ†å‰²æˆ {len(docs)} ä¸ªå—")
                            st.balloons()
                            
                            # æ¸…é™¤ç¼“å­˜çš„ retriever
                            if 'retriever' in st.session_state:
                                del st.session_state.retriever
                            
                except Exception as e:
                    st.error(f"âŒ æ„å»ºå¤±è´¥: {e}")
                    st.code(str(e), language="python")

# --- é¡µé¢æ¸²æŸ“ ---
if st.session_state.page == "çŸ¥è¯†åº“é—®ç­”":
    # é¡µé¢å¤´éƒ¨å¡ç‰‡ - æ”¹ä¸ºæ²‰ç¨³çš„æ·±è“ç°è‰²
    st.markdown("""
    <div style='background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%); 
                padding: 20px; border-radius: 10px; margin-bottom: 20px;'>
        <h2 style='color: white; margin: 0;'>ğŸ’¬ æ™ºèƒ½çŸ¥è¯†åº“é—®ç­”</h2>
        <p style='color: rgba(255,255,255,0.9); margin: 5px 0 0 0;'>åŸºäºå†…éƒ¨çŸ¥è¯†æ–‡æ¡£ï¼Œæä¾›ç²¾å‡†çš„é—®ç­”èƒ½åŠ›ã€‚å¦‚æœæ–‡æ¡£æ— ç›¸å…³ä¿¡æ¯ï¼Œå°†ç”±å¤§æ¨¡å‹æä¾›é€šç”¨å›ç­”ã€‚</p>
    </div>
    """, unsafe_allow_html=True)

    with st.container(border=True):
        if not os.getenv("DASHSCOPE_API_KEY"):
            st.error("é”™è¯¯ï¼šè¯·å…ˆè®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡ã€‚")
            st.code("export DASHSCOPE_API_KEY='æ‚¨çš„key'", language="shell")
        else:
            # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å’Œå¼€åœºç™½
            if "messages" not in st.session_state:
                st.session_state.messages = [{"role": "assistant", "content": JA_ASSISTANT_INTRO}]

            # åˆ›å»ºä¸€ä¸ªå®¹å™¨æ¥å±•ç¤ºèŠå¤©è®°å½•
            chat_box = st.container(height=400)

            # åœ¨å®¹å™¨ä¸­æ˜¾ç¤ºå†å²æ¶ˆæ¯
            for message in st.session_state.messages:
                with chat_box.chat_message(message["role"]):
                    st.markdown(message["content"])
            
            # èŠå¤©è¾“å…¥æ¡†
            if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
                # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°å†å²å¹¶ç«‹å³æ˜¾ç¤ºåœ¨å®¹å™¨ä¸­
                st.session_state.messages.append({"role": "user", "content": prompt})
                with chat_box.chat_message("user"):
                    st.markdown(prompt)
                
                # è·å–å¹¶æ˜¾ç¤ºåŠ©æ‰‹çš„å›å¤
                with chat_box.chat_message("assistant"):
                    with st.spinner("æ­£åœ¨æ€è€ƒ..."):
                        if 'retriever' not in st.session_state:
                            with st.spinner("æ­£åœ¨åˆå§‹åŒ–çŸ¥è¯†åº“ï¼Œè¯·ç¨å€™..."):
                                st.session_state.retriever = get_retriever()
                        retriever = st.session_state.retriever

                        if not retriever:
                            st.error("çŸ¥è¯†åº“ç´¢å¼•æœªæ‰¾åˆ°æˆ–åŠ è½½å¤±è´¥ï¼è¯·æ£€æŸ¥faiss_indexç›®å½•æˆ–è¿è¡Œ `build_knowledge_base.py`ã€‚")
                            st.stop()

                        # RAGé€»è¾‘...
                        with st.spinner("æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“å¹¶ç”Ÿæˆå›ç­”..."):
                            relevant_docs = retriever.get_relevant_documents(prompt)
                        use_rag = False
                        if relevant_docs:
                            context_string = "\n\n".join(doc.page_content for doc in relevant_docs)
                            validate_messages = [
                                {"role": "system", "content": "You are a helpful assistant."},
                                {"role": "user", "content": f"ä»…æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡ï¼š\n\n{context_string}\n\nåˆ¤æ–­æ˜¯å¦å¯ä»¥å›ç­”è¿™ä¸ªé—®é¢˜ï¼š'{prompt}'ï¼Ÿè¯·åªå›ç­”'æ˜¯'æˆ–'å¦'ã€‚"}
                            ]
                            validation_result = call_qwen_model(validate_messages)
                            if "æ˜¯" in validation_result:
                                use_rag = True
                        
                        if use_rag:
                            st.info("âœ… AIåˆ¤æ–­ä¿¡æ¯ç›¸å…³ï¼Œå°†åŸºäºçŸ¥è¯†åº“å›ç­”...")
                            system_content = f"{JA_ASSISTANT_PERSONA} è¯·ä¸¥æ ¼æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡æ¥å›ç­”é—®é¢˜ï¼Œå›ç­”æ—¶å¯ä»¥å¯¹ä¿¡æ¯è¿›è¡Œæ€»ç»“å’Œç»„ç»‡ï¼Œä½†ä¸è¦è¶…å‡ºä¸Šä¸‹æ–‡èŒƒå›´:\n{context_string}"
                            messages = [{"role": "system", "content": system_content}, {"role": "user", "content": prompt}]
                            response = call_qwen_model(messages)
                        else:
                            st.warning("âš ï¸ AIåˆ¤æ–­çŸ¥è¯†åº“ä¸­æ— ç›´æ¥ç›¸å…³ä¿¡æ¯ï¼Œå°†ä½¿ç”¨é€šç”¨çŸ¥è¯†å›ç­”...")
                            messages = [{"role": "system", "content": JA_ASSISTANT_GENERAL_KNOWLEDGE_PERSONA}, {"role": "user", "content": prompt}]
                            response = call_qwen_model(messages)
                        
                        st.markdown(response)
                        # å°†åŠ©æ‰‹å›å¤ä¹Ÿæ·»åŠ åˆ°ä¼šè¯çŠ¶æ€
                        st.session_state.messages.append({"role": "assistant", "content": response})

elif st.session_state.page == "æ–‡çŒ®æ£€ç´¢":
    # é¡µé¢å¤´éƒ¨å¡ç‰‡ - æ”¹ä¸ºæ²‰ç¨³çš„æ·±ç»¿è‰²
    st.markdown("""
    <div style='background: linear-gradient(135deg, #16a085 0%, #1abc9c 100%); 
                padding: 20px; border-radius: 10px; margin-bottom: 20px;'>
        <h2 style='color: white; margin: 0;'>ğŸ“° æœ€æ–°ç§‘ç ”æ–‡çŒ®è¿½è¸ª</h2>
        <p style='color: rgba(255,255,255,0.9); margin: 5px 0 0 0;'>è¾“å…¥å…³é”®è¯ï¼ŒAIå°†è‡ªåŠ¨ä»arXivä¸Šæ£€ç´¢æœ€æ–°çš„ç›¸å…³è®ºæ–‡ï¼Œå¹¶ç”Ÿæˆç®€æŠ¥ã€‚</p>
    </div>
    """, unsafe_allow_html=True)

    # åˆå§‹åŒ–AIæ‘˜è¦çš„çŠ¶æ€å­˜å‚¨
    if 'ai_summaries' not in st.session_state:
        st.session_state.ai_summaries = {}
    if 'search_results' not in st.session_state:
        st.session_state.search_results = None

    with st.container(border=True):
        # ä½¿ç”¨åˆ—æ¥å¸ƒå±€è¾“å…¥æ¡†å’Œé€‰æ‹©å™¨
        col1, col2, col3 = st.columns([3, 1, 1])
        with col1:
            keywords_input = st.text_input(
                "è¯·è¾“å…¥å…³é”®è¯ï¼ˆå¤šä¸ªè¯·ç”¨è‹±æ–‡é€—å·,éš”å¼€ï¼‰:", 
                value="perovskite stability, CsPbI3",
                help="ä¾‹å¦‚: perovskite solar cell, ETL, device stability"
            )
        with col2:
            date_range = st.selectbox(
                "æ—¶é—´èŒƒå›´",
                ("all_time", "last_month", "last_3_months", "last_year"),
                format_func=lambda x: {
                    "all_time": "æ‰€æœ‰æ—¶é—´",
                    "last_month": "æœ€è¿‘ä¸€ä¸ªæœˆ",
                    "last_3_months": "æœ€è¿‘ä¸‰ä¸ªæœˆ",
                    "last_year": "æœ€è¿‘ä¸€å¹´"
                }.get(x),
            )
        with col3:
            sort_by = st.selectbox(
                "æ’åºæ–¹å¼",
                ("Relevance", "SubmittedDate"),
                index=1, # é»˜è®¤é€‰æ‹©â€œæœ€æ–°å‘è¡¨â€
                format_func=lambda x: {"Relevance": "ç›¸å…³åº¦", "SubmittedDate": "æœ€æ–°å‘è¡¨"}.get(x)
            )

        if st.button("å¼€å§‹æ£€ç´¢", use_container_width=True):
            # æ¸…ç©ºä¹‹å‰çš„AIæ‘˜è¦å’Œç»“æœ
            st.session_state.ai_summaries = {}
            st.session_state.search_results = None
            st.session_state.search_error = None
            if keywords_input:
                keywords_list = [keyword.strip() for keyword in keywords_input.split(',') if keyword.strip()]
                with st.spinner(f"æ­£åœ¨ä»arXivæ£€ç´¢: {', '.join(keywords_list)}...\nè¯·è€å¿ƒç­‰å¾…ï¼Œæ£€ç´¢å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ã€‚"):
                    papers, error = get_latest_papers(keywords_list, date_range, sort_by)
                    # å°†ç»“æœå­˜å‚¨åœ¨session stateä¸­ï¼Œä»¥ä¾¿åœ¨æŒ‰é’®ç‚¹å‡»åä¿ç•™
                    st.session_state.search_results = papers
                    st.session_state.search_error = error
            else:
                st.warning("è¯·è¾“å…¥å…³é”®è¯ã€‚")

    # åœ¨ä¸»æŒ‰é’®é€»è¾‘å¤–éƒ¨æ¸²æŸ“ç»“æœï¼Œä»¥æ”¯æŒAIæ€»ç»“æŒ‰é’®çš„äº¤äº’
    if st.session_state.search_results:
        papers = st.session_state.search_results
        st.success(f"æ£€ç´¢å®Œæˆï¼å…±æ‰¾åˆ° {len(papers)} ç¯‡ç›¸å…³è®ºæ–‡ã€‚")
        
        for i, paper in enumerate(papers):
            with st.expander(f"**{i+1}. {paper['title']}**", expanded=True):
                st.markdown(f"**å‘è¡¨æ—¥æœŸ:** {paper['published']} | **ä½œè€…:** {paper['authors']}")
                st.markdown(f"**æ‘˜è¦:** {paper['summary']}")
                
                # åŠŸèƒ½æŒ‰é’® - ä¼˜åŒ–å¸ƒå±€
                col1, col2, col3 = st.columns(3, gap="small")
                with col1:
                    pdf_url = paper.get('pdf_url', '')
                    if pdf_url and isinstance(pdf_url, str) and pdf_url.strip():
                        st.link_button("é˜…è¯»åŸæ–‡", pdf_url, use_container_width=True)
                    else:
                        st.button("é˜…è¯»åŸæ–‡ï¼ˆæš‚æ— é“¾æ¥ï¼‰", disabled=True, use_container_width=True)
                with col2:
                    if st.button("AIæ€»ç»“", key=f"summarize_{paper['entry_id']}", use_container_width=True):
                        with st.spinner("AIæ­£åœ¨é˜…è¯»æ‘˜è¦ï¼Œè¯·ç¨å€™..."):
                            ai_summary = summarize_with_ai(paper['summary'])
                            st.session_state.ai_summaries[paper['entry_id']] = ai_summary
                with col3:
                    if st.button("æ·±å…¥ç ”ç©¶", key=f"research_{paper['entry_id']}", use_container_width=True):
                        st.toast("è¯¥åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­...")

                # å¦‚æœå­˜åœ¨AIæ€»ç»“ï¼Œåˆ™æ˜¾ç¤ºå®ƒ
                if paper['entry_id'] in st.session_state.ai_summaries:
                    st.info(f"{st.session_state.ai_summaries[paper['entry_id']]}")

    elif st.session_state.get('search_error'):
        st.error(st.session_state.search_error)
    # åªæœ‰åœ¨æŒ‰é’®è¢«ç‚¹å‡»åï¼Œsearch_resultsæ‰ä¼šè¢«å®šä¹‰ï¼Œæ‰€ä»¥éœ€è¦æ£€æŸ¥
    elif st.session_state.get('search_results') is not None and not st.session_state.get('search_results'):
        st.warning("åœ¨é€‰å®šæ—¶é—´èŒƒå›´å†…ï¼Œæœªæ‰¾åˆ°ä¸æ‚¨å…³é”®è¯ç›¸å…³çš„æ–°è®ºæ–‡ã€‚")

elif st.session_state.page == "æ–‡çŒ®è®¢é˜…":
    # é¡µé¢å¤´éƒ¨å¡ç‰‡
    st.markdown("""
    <div style='background: linear-gradient(135deg, #8e44ad 0%, #9b59b6 100%); 
                padding: 20px; border-radius: 10px; margin-bottom: 20px;'>
        <h2 style='color: white; margin: 0;'>ğŸ”” æ–‡çŒ®è®¢é˜…ç®¡ç†</h2>
        <p style='color: rgba(255,255,255,0.9); margin: 5px 0 0 0;'>è®¢é˜…æ„Ÿå…´è¶£çš„ç ”ç©¶é¢†åŸŸï¼Œç³»ç»Ÿå°†å®šæ—¶æ¨é€æœ€æ–°è®ºæ–‡æ›´æ–°ã€‚</p>
    </div>
    """, unsafe_allow_html=True)
    
    # è·å–è®¢é˜…ç®¡ç†å™¨
    sub_manager = get_subscription_manager()
    
    # åˆå§‹åŒ– active_tab
    if 'active_subscription_tab' not in st.session_state:
        st.session_state.active_subscription_tab = 0
    
    # å¦‚æœä»ä¾§è¾¹æ è·³è½¬è¿‡æ¥ï¼Œæ˜¾ç¤ºæœªè¯»æ›´æ–°é¡µé¢
    if st.session_state.active_subscription_tab == 2:
        # è®¾ç½®æ ‡å¿—ï¼Œä½†ä¸ç«‹å³é‡ç½®ï¼Œé¿å…æŒ‰é’®ç‚¹å‡»åè·³è½¬
        show_unread_first = True
    else:
        show_unread_first = False
    
    # å¦‚æœéœ€è¦å…ˆæ˜¾ç¤ºæœªè¯»æ›´æ–°
    if show_unread_first:
        st.subheader("ğŸ”” æœªè¯»æ–‡çŒ®æ›´æ–°")
        st.info("ğŸ’¬ ä»¥ä¸‹æ˜¯æ‚¨æ‰€æœ‰è®¢é˜…çš„æœ€è¿‘æ›´æ–°")
        
        all_subscriptions = sub_manager.get_subscriptions(enabled_only=True)
        total_unread = 0
        
        for sub in all_subscriptions:
            history = sub_manager.get_update_history(sub['id'], limit=1)
            if history and history[-1]['paper_count'] > 0:
                latest_check = history[-1]
                papers = latest_check['papers']
                total_unread += len(papers)
                
                with st.expander(f"ğŸ“ **{sub['name']}** - {len(papers)} ç¯‡æ–°è®ºæ–‡", expanded=True):
                    st.caption(f"ğŸ“… æ£€æŸ¥æ—¶é—´ï¼š{latest_check['check_time'][:16]}")
                    
                    for i, paper in enumerate(papers):
                        with st.container(border=True):
                            st.markdown(f"**{i+1}. {paper['title']}**")
                            st.caption(f"ğŸ“… {paper['published']} | âœï¸ {paper['authors'][:100]}...")
                            st.markdown(f"{paper['summary'][:200]}...")
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                pdf_url = paper.get('pdf_url', '')
                                if pdf_url and isinstance(pdf_url, str) and pdf_url.strip():
                                    st.link_button("ğŸ“ é˜…è¯»åŸæ–‡", pdf_url, use_container_width=True)
                            with col2:
                                # ä¸ºæœªè¯»æ›´æ–°çš„ AI æ€»ç»“æŒ‰é’®ä½¿ç”¨ç‹¬ç«‹çš„ key
                                unread_key = f"unread_summary_{sub['id']}_{i}"
                                if st.button("ğŸ¤– AIæ€»ç»“", key=unread_key, use_container_width=True):
                                    with st.spinner("ğŸ¤– AIæ­£åœ¨é˜…è¯»æ‘˜è¦..."):
                                        ai_summary = summarize_with_ai(paper['summary'])
                                        # ä¿å­˜åˆ° session_state
                                        if 'unread_ai_summaries' not in st.session_state:
                                            st.session_state.unread_ai_summaries = {}
                                        st.session_state.unread_ai_summaries[unread_key] = ai_summary
                                        st.rerun()
                            
                            # æ˜¾ç¤º AI æ€»ç»“ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                            if 'unread_ai_summaries' in st.session_state:
                                unread_key = f"unread_summary_{sub['id']}_{i}"
                                if unread_key in st.session_state.unread_ai_summaries:
                                    st.info(f"ğŸ¤– {st.session_state.unread_ai_summaries[unread_key]}")
        
        if total_unread == 0:
            st.success("âœ… æš‚æ— æœªè¯»æ›´æ–°ï¼")
        
        st.markdown("---")
        st.caption("ğŸ‘‡ æ‚¨å¯ä»¥åœ¨ä¸‹æ–¹ç®¡ç†è®¢é˜…æˆ–æ‰‹åŠ¨æ£€æŸ¥æ›´æ–°")
    
    # åˆ›å»ºæ ‡ç­¾é¡µï¼šè®¢é˜…ç®¡ç†ã€æ·»åŠ è®¢é˜…ã€æ£€æŸ¥æ›´æ–°
    tab1, tab2, tab3 = st.tabs(["ğŸ“ æˆ‘çš„è®¢é˜…", "â• æ·»åŠ è®¢é˜…", "ğŸ” æ£€æŸ¥æ›´æ–°"])
    
    with tab1:
        st.subheader("ğŸ“š è®¢é˜…åˆ—è¡¨")
        
        subscriptions = sub_manager.get_subscriptions()
        
        if not subscriptions:
            st.info("ğŸ’­ æ‚¨è¿˜æ²¡æœ‰ä»»ä½•è®¢é˜…ã€‚è¯·åˆ°'æ·»åŠ è®¢é˜…'æ ‡ç­¾é¡µåˆ›å»ºæ‚¨çš„ç¬¬ä¸€ä¸ªè®¢é˜…ï¼")
        else:
            # ç»Ÿè®¡ä¿¡æ¯
            stats = sub_manager.get_statistics()
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æ€»è®¢é˜…æ•°", stats["total_subscriptions"])
            with col2:
                st.metric("å¯ç”¨ä¸­", stats["enabled_subscriptions"])
            with col3:
                st.metric("å·²å‘ç°è®ºæ–‡", stats["total_papers_found"])
            
            st.markdown("---")
            
            # æ˜¾ç¤ºæ¯ä¸ªè®¢é˜…
            for sub in subscriptions:
                with st.expander(f"{'âœ…' if sub.get('enabled') else 'âŒ'} **{sub['name']}**", expanded=True):
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        st.markdown(f"**å…³é”®è¯:** {', '.join(sub['keywords'])}")
                        st.caption(f"ğŸ“… åˆ›å»ºäº: {sub['created_at'][:10]}")
                        if sub.get('last_checked'):
                            st.caption(f"ğŸ” æœ€åæ£€æŸ¥: {sub['last_checked'][:16]}")
                            st.caption(f"ğŸ“§ é€šçŸ¥æ•°: {sub.get('notification_count', 0)} ç¯‡")
                        else:
                            st.caption("ğŸ” æœ€åæ£€æŸ¥: ä»æœªæ£€æŸ¥")
                    
                    with col2:
                        # å¯ç”¨/ç¦ç”¨åˆ‡æ¢
                        is_enabled = st.checkbox(
                            "å¯ç”¨",
                            value=sub.get('enabled', True),
                            key=f"enable_{sub['id']}"
                        )
                        if is_enabled != sub.get('enabled', True):
                            sub_manager.update_subscription(sub['id'], enabled=is_enabled)
                            st.rerun()
                        
                        # åˆ é™¤æŒ‰é’®
                        if st.button("ğŸ—‘ï¸ åˆ é™¤", key=f"delete_{sub['id']}", type="secondary", use_container_width=True):
                            if sub_manager.remove_subscription(sub['id']):
                                st.success(f"âœ… å·²åˆ é™¤è®¢é˜… '{sub['name']}'")
                                st.rerun()
                            else:
                                st.error("âŒ åˆ é™¤å¤±è´¥")
                    
                    # ç¼–è¾‘åŠŸèƒ½
                    with st.form(key=f"edit_form_{sub['id']}"):
                        st.caption("âœï¸ ç¼–è¾‘è®¢é˜…")
                        new_name = st.text_input("è®¢é˜…åç§°", value=sub['name'], key=f"name_{sub['id']}")
                        new_keywords = st.text_input(
                            "å…³é”®è¯ï¼ˆè‹±æ–‡é€—å·åˆ†éš”ï¼‰",
                            value=", ".join(sub['keywords']),
                            key=f"keywords_{sub['id']}"
                        )
                        
                        if st.form_submit_button("ğŸ’¾ ä¿å­˜ä¿®æ”¹", use_container_width=True):
                            keywords_list = [k.strip() for k in new_keywords.split(',') if k.strip()]
                            if new_name and keywords_list:
                                if sub_manager.update_subscription(sub['id'], name=new_name, keywords=keywords_list):
                                    st.success("âœ… æ›´æ–°æˆåŠŸï¼")
                                    st.rerun()
                                else:
                                    st.error("âŒ æ›´æ–°å¤±è´¥")
                            else:
                                st.warning("âš ï¸ è¯·å¡«å†™å®Œæ•´ä¿¡æ¯")
    
    with tab2:
        st.subheader("â• åˆ›å»ºæ–°è®¢é˜…")
        
        with st.form(key="add_subscription_form"):
            st.markdown("ğŸ”– å¡«å†™ä»¥ä¸‹ä¿¡æ¯åˆ›å»ºæ‚¨çš„æ–‡çŒ®è®¢é˜…")
            
            sub_name = st.text_input(
                "ğŸ·ï¸ è®¢é˜…åç§°",
                placeholder="ä¾‹å¦‚ï¼šé’—é’›çŸ¿ç¨³å®šæ€§ç ”ç©¶",
                help="ç»™æ‚¨çš„è®¢é˜…èµ·ä¸€ä¸ªæœ‰æ„ä¹‰çš„åå­—"
            )
            
            sub_keywords = st.text_area(
                "ğŸ”‘ å…³é”®è¯ï¼ˆè‹±æ–‡é€—å·åˆ†éš”ï¼‰",
                placeholder="ä¾‹å¦‚ï¼šperovskite stability, CsPbI3, long-term stability",
                help="è¾“å…¥æ‚¨æƒ³è·Ÿè¸ªçš„ç ”ç©¶å…³é”®è¯ï¼Œå¤šä¸ªå…³é”®è¯ç”¨è‹±æ–‡é€—å·åˆ†éš”",
                height=100
            )
            
            enabled = st.checkbox("âœ… ç«‹å³å¯ç”¨è¯¥è®¢é˜…", value=True)
            
            st.info("ğŸ’¡ æç¤ºï¼šç³»ç»Ÿå°†æ¯å¤©24å°æ—¶è‡ªåŠ¨æ£€æŸ¥è®¢é˜…æ›´æ–°ï¼Œæ‚¨ä¹Ÿå¯ä»¥éšæ—¶åœ¨'æ£€æŸ¥æ›´æ–°'æ ‡ç­¾é¡µæ‰‹åŠ¨æ£€æŸ¥ã€‚")
            
            col1, col2 = st.columns(2)
            with col1:
                submit_button = st.form_submit_button("ğŸ‰ åˆ›å»ºè®¢é˜…", use_container_width=True, type="primary")
            with col2:
                if st.form_submit_button("ğŸ”„ æ¸…ç©º", use_container_width=True):
                    st.rerun()
            
            if submit_button:
                if sub_name and sub_keywords:
                    keywords_list = [k.strip() for k in sub_keywords.split(',') if k.strip()]
                    if keywords_list:
                        if sub_manager.add_subscription(sub_name, keywords_list, enabled):
                            st.success(f"âœ… è®¢é˜… '{sub_name}' åˆ›å»ºæˆåŠŸï¼")
                            st.balloons()
                            st.rerun()
                        else:
                            st.error("âŒ åˆ›å»ºå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•")
                    else:
                        st.warning("âš ï¸ è¯·è‡³å°‘è¾“å…¥ä¸€ä¸ªå…³é”®è¯")
                else:
                    st.warning("âš ï¸ è¯·å¡«å†™å®Œæ•´ä¿¡æ¯")
    
    with tab3:
        st.subheader("ğŸ” æ£€æŸ¥è®¢é˜…æ›´æ–°")
        
        # åˆå§‹åŒ– session_state
        if 'subscription_papers' not in st.session_state:
            st.session_state.subscription_papers = None
        if 'subscription_error' not in st.session_state:
            st.session_state.subscription_error = None
        if 'subscription_ai_summaries' not in st.session_state:
            st.session_state.subscription_ai_summaries = {}
        if 'auto_refresh_enabled' not in st.session_state:
            st.session_state.auto_refresh_enabled = False
        if 'refresh_interval' not in st.session_state:
            st.session_state.refresh_interval = 300  # é»˜è®¤ 5 åˆ†é’Ÿ
        
        subscriptions = sub_manager.get_subscriptions(enabled_only=True)
        
        if not subscriptions:
            st.info("ğŸ’­ æ‚¨æ²¡æœ‰å¯ç”¨çš„è®¢é˜…ã€‚")
        else:
            # è‡ªåŠ¨åˆ·æ–°é…ç½®
            with st.expander("âš™ï¸ è‡ªåŠ¨åˆ·æ–°è®¾ç½®", expanded=False):
                col1, col2 = st.columns([2, 1])
                with col1:
                    auto_refresh = st.toggle(
                        "ğŸ”„ å¯ç”¨è‡ªåŠ¨åˆ·æ–°",
                        value=st.session_state.auto_refresh_enabled,
                        help="å¼€å¯åï¼Œé¡µé¢å°†æŒ‰è®¾å®šçš„é—´éš”è‡ªåŠ¨æ£€æŸ¥æ›´æ–°"
                    )
                    if auto_refresh != st.session_state.auto_refresh_enabled:
                        st.session_state.auto_refresh_enabled = auto_refresh
                        st.rerun()
                
                with col2:
                    interval_options = {
                        "æ¯ 5 åˆ†é’Ÿ": 300,
                        "æ¯ 15 åˆ†é’Ÿ": 900,
                        "æ¯ 30 åˆ†é’Ÿ": 1800,
                        "æ¯ 1 å°æ—¶": 3600,
                    }
                    selected_interval = st.selectbox(
                        "åˆ·æ–°é—´éš”",
                        options=list(interval_options.keys()),
                        index=0,
                        disabled=not auto_refresh
                    )
                    st.session_state.refresh_interval = interval_options[selected_interval]
                
                if auto_refresh:
                    st.info(f"âœ… è‡ªåŠ¨åˆ·æ–°å·²å¯ç”¨ï¼Œé—´éš”ï¼š{selected_interval}")
                    # ä½¿ç”¨ time.sleep å®ç°è‡ªåŠ¨åˆ·æ–°
                    import time
                    time.sleep(st.session_state.refresh_interval)
                    st.rerun()
            
            st.markdown("---")
            # é€‰æ‹©è¦æ£€æŸ¥çš„è®¢é˜…
            sub_options = {f"{sub['name']} ({', '.join(sub['keywords'][:2])}...)": sub['id'] for sub in subscriptions}
            selected_sub_name = st.selectbox(
                "ğŸ¯ é€‰æ‹©è¦æ£€æŸ¥çš„è®¢é˜…",
                options=list(sub_options.keys())
            )
            selected_sub_id = sub_options[selected_sub_name]
            
            # æ—¶é—´èŒƒå›´é€‰æ‹©
            days_back = st.slider(
                "ğŸ“… æ£€æŸ¥è¿‡å»å‡ å¤©çš„è®ºæ–‡",
                min_value=1,
                max_value=7,
                value=1,
                help="é€‰æ‹©è¦æ£€æŸ¥çš„æ—¶é—´èŒƒå›´"
            )
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸ” å¼€å§‹æ£€æŸ¥", use_container_width=True, type="primary"):
                    # æ¸…ç©ºä¹‹å‰çš„ç»“æœå’Œ AI æ€»ç»“
                    st.session_state.subscription_ai_summaries = {}
                    with st.spinner(f"ğŸ” æ­£åœ¨æ£€æŸ¥è¿‡å» {days_back} å¤©çš„æ–°è®ºæ–‡...\nè¯·è€å¿ƒç­‰å¾…ï¼Œæ£€ç´¢å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ã€‚"):
                        papers, error = sub_manager.check_for_updates(selected_sub_id, days_back)
                        
                        # ä¿å­˜åˆ° session_state
                        st.session_state.subscription_papers = papers
                        st.session_state.subscription_error = error
                        st.session_state.subscription_info = {
                            'sub_id': selected_sub_id,
                            'days_back': days_back
                        }
            
            with col2:
                if st.button("ğŸ“„ æŸ¥çœ‹å†å²è®°å½•", use_container_width=True):
                    history = sub_manager.get_update_history(selected_sub_id, limit=5)
                    if history:
                        st.subheader("ğŸ“œ æ£€æŸ¥å†å²ï¼ˆæœ€è¿‘ 5 æ¬¡ï¼‰")
                        for record in reversed(history):
                            with st.expander(f"ğŸ“… {record['check_time'][:16]} - {record['paper_count']} ç¯‡"):
                                for paper in record['papers'][:3]:
                                    st.markdown(f"- {paper['title'][:60]}...")
                                if len(record['papers']) > 3:
                                    st.caption(f"... è¿˜æœ‰ {len(record['papers']) - 3} ç¯‡")
                    else:
                        st.info("æš‚æ— å†å²è®°å½•")
            
            # æ˜¾ç¤ºæ£€ç´¢ç»“æœï¼ˆä» session_state ä¸­è¯»å–ï¼‰
            if st.session_state.subscription_error:
                st.error(f"âŒ {st.session_state.subscription_error}")
            elif st.session_state.subscription_papers is not None:
                papers = st.session_state.subscription_papers
                if papers:
                    subscription = sub_manager.get_subscription(st.session_state.subscription_info['sub_id'])
                    days_back = st.session_state.subscription_info['days_back']
                    
                    st.success(f"âœ… å‘ç° {len(papers)} ç¯‡æ–°è®ºæ–‡ï¼")
                    
                    # æ˜¾ç¤ºé€šçŸ¥æ¶ˆæ¯
                    notification = format_notification(subscription, papers)
                    st.info(notification)
                    
                    st.markdown("---")
                    st.subheader("ğŸ“š è®ºæ–‡è¯¦æƒ…")
                    
                    # æ˜¾ç¤ºæ‰€æœ‰è®ºæ–‡
                    for i, paper in enumerate(papers, 1):
                        with st.expander(f"**{i}. {paper['title']}**", expanded=(i <= 3)):
                            st.markdown(f"**å‘è¡¨æ—¥æœŸ:** {paper['published']} | **ä½œè€…:** {paper['authors']}")
                            st.markdown(f"**åŒ¹é…å…³é”®è¯:** {paper.get('keyword', 'N/A')}")
                            st.markdown(f"**æ‘˜è¦:** {paper['summary'][:300]}...")
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                pdf_url = paper.get('pdf_url', '')
                                if pdf_url and isinstance(pdf_url, str) and pdf_url.strip():
                                    st.link_button("ğŸ“ é˜…è¯»åŸæ–‡", pdf_url, use_container_width=True)
                                else:
                                    st.button("ğŸ“ é˜…è¯»åŸæ–‡ï¼ˆæš‚æ— é“¾æ¥ï¼‰", disabled=True, use_container_width=True)
                            with col2:
                                if st.button("ğŸ¤– AIæ€»ç»“", key=f"sub_summary_{paper['entry_id']}", use_container_width=True):
                                    with st.spinner("AIæ­£åœ¨é˜…è¯»æ‘˜è¦ï¼Œè¯·ç¨å€™..."):
                                        ai_summary = summarize_with_ai(paper['summary'])
                                        st.session_state.subscription_ai_summaries[paper['entry_id']] = ai_summary
                                        st.rerun()
                            
                            # æ˜¾ç¤º AI æ€»ç»“ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                            if paper['entry_id'] in st.session_state.subscription_ai_summaries:
                                st.info(f"ğŸ¤– {st.session_state.subscription_ai_summaries[paper['entry_id']]}")
                elif st.session_state.subscription_info:
                    days_back = st.session_state.subscription_info['days_back']
                    st.warning(f"ğŸ” åœ¨è¿‡å» {days_back} å¤©å†…æœªå‘ç°æ–°è®ºæ–‡ã€‚")

elif st.session_state.page == "XRDåˆ†æ":
    # é¡µé¢å¤´éƒ¨å¡ç‰‡ - æ”¹ä¸ºæ²‰ç¨³çš„æ·±è“è‰²
    st.markdown("""
    <div style='background: linear-gradient(135deg, #2980b9 0%, #3498db 100%); 
                padding: 20px; border-radius: 10px; margin-bottom: 20px;'>
        <h2 style='color: white; margin: 0;'>ğŸ“ˆ XRDæ•°æ®è‡ªåŠ¨åˆ†æ</h2>
        <p style='color: rgba(255,255,255,0.9); margin: 5px 0 0 0;'>ä¸Šä¼ æ‚¨çš„åŸå§‹XRDæ•°æ®æ–‡ä»¶ï¼ˆtxtæˆ–csvæ ¼å¼ï¼‰ï¼ŒAIå°†è‡ªåŠ¨ç»˜åˆ¶å›¾è°±å¹¶è¯†åˆ«ä¸»è¦è¡å°„å³°ã€‚</p>
    </div>
    """, unsafe_allow_html=True)

    with st.container(border=True):
        uploaded_file = st.file_uploader(
            "è¯·åœ¨æ­¤å¤„ä¸Šä¼ æ‚¨çš„XRDæ•°æ®æ–‡ä»¶", 
            type=["txt", "csv"],
            label_visibility="collapsed"
        )
        if uploaded_file:
            with st.spinner("æ­£åœ¨åˆ†æå›¾è°±..."):
                fig = analyze_xrd_from_upload(uploaded_file)
                if fig:
                    st.pyplot(fig)
                    st.success("å›¾è°±ç”Ÿæˆå®Œæ¯•ï¼")

elif st.session_state.page == "æ€§èƒ½é¢„æµ‹":
    # é¡µé¢å¤´éƒ¨å¡ç‰‡ - æ”¹ä¸ºæ²‰ç¨³çš„æ·±ç»¿ç°è‰²
    st.markdown("""
    <div style='background: linear-gradient(135deg, #27ae60 0%, #2ecc71 100%); 
                padding: 20px; border-radius: 10px; margin-bottom: 20px;'>
        <h2 style='color: white; margin: 0;'>ğŸ’¡ ææ–™æ€§èƒ½é¢„æµ‹</h2>
        <p style='color: rgba(255,255,255,0.9); margin: 5px 0 0 0;'>è°ƒæ•´ä»¥ä¸‹å®éªŒå‚æ•°ï¼ŒAIæ¨¡å‹å°†é¢„æµ‹å¯¹åº”çš„å…‰ç”µè½¬æ¢æ•ˆç‡ã€‚</p>
    </div>
    """, unsafe_allow_html=True)
    
    model = get_trained_model()
    if model:
        # ä½¿ç”¨å¸¦è¾¹æ¡†çš„å®¹å™¨æ¥ç»„ç»‡UI
        with st.container(border=True):
            col1, col2, col3 = st.columns(3)
            with col1:
                rpm = st.slider("æ—‹æ¶‚é€Ÿåº¦ (rpm)", 2000, 6000, 4000, 100)
            with col2:
                temp = st.slider("é€€ç«æ¸©åº¦ (Â°C)", 80, 140, 100, 5)
            with col3:
                conc = st.slider("æ·»åŠ å‰‚æµ“åº¦ (%)", 0.1, 2.0, 1.0, 0.1)
        
        # å°†æŒ‰é’®å’Œç»“æœä¹Ÿæ”¾åœ¨ä¸€ä¸ªå®¹å™¨ä¸­
        with st.container(border=True):
            if st.button("æ‰§è¡Œé¢„æµ‹", use_container_width=True):
                new_params = pd.DataFrame({
                    'spin_coating_rpm': [rpm],
                    'annealing_temperature_C': [temp],
                    'additive_concentration_percent': [conc]
                })
                prediction = model.predict(new_params)
                st.metric(label="é¢„æµ‹æ•ˆç‡", value=f"{prediction[0]:.2f} %")
    else:
        st.error("æ•°æ®æ–‡ä»¶ 'simulated_experimental_data.csv' ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹ã€‚")

elif st.session_state.page == "å®éªŒä¼˜åŒ–":
    # é¡µé¢å¤´éƒ¨å¡ç‰‡ - æ”¹ä¸ºæ²‰ç¨³çš„æ·±æ©™ç°è‰²
    st.markdown("""
    <div style='background: linear-gradient(135deg, #d35400 0%, #e67e22 100%); 
                padding: 20px; border-radius: 10px; margin-bottom: 20px;'>
        <h2 style='color: white; margin: 0;'>ğŸš€ å®éªŒæ–¹æ¡ˆä¼˜åŒ–</h2>
        <p style='color: rgba(255,255,255,0.9); margin: 5px 0 0 0;'>AIå°†æœç´¢å¤šç§å‚æ•°ç»„åˆï¼Œä¸ºæ‚¨æ¨èèƒ½äº§ç”Ÿæœ€é«˜æ•ˆç‡çš„'æœ€ä½³å®éªŒæ–¹æ¡ˆ'ã€‚</p>
    </div>
    """, unsafe_allow_html=True)
    
    model = get_trained_model()
    if model:
        with st.container(border=True):
            st.info("è¯·æ³¨æ„ï¼šä¸ºä¿è¯å¿«é€Ÿå“åº”ï¼Œæ¼”ç¤ºç‰ˆçš„æœç´¢ç©ºé—´è¾ƒå°ã€‚åœ¨è·å–æ›´å¤šçœŸå®æ•°æ®åï¼Œå¯æ‰©å±•æœç´¢èŒƒå›´ä»¥è·å¾—æ›´ä¼˜ç»“æœã€‚")
            if st.button("å¼€å§‹ä¼˜åŒ–ï¼Œå¯»æ‰¾æœ€ä½³å‚æ•°", use_container_width=True):
                with st.spinner("æ­£åœ¨è¿›è¡Œç½‘æ ¼æœç´¢ä¼˜åŒ–..."):
                    params, eff = find_optimal_params(model)
                    st.success("ä¼˜åŒ–å®Œæˆï¼")
                    st.metric(label="æœ€é«˜é¢„æµ‹æ•ˆç‡", value=f"{eff:.2f} %")
                    
                    st.write("AIæ¨èçš„æœ€ä½³å®éªŒå‚æ•°ç»„åˆä¸º:")
                    st.table(params)
    else:
        st.error("æ•°æ®æ–‡ä»¶ 'simulated_experimental_data.csv' ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡Œä¼˜åŒ–ã€‚")
